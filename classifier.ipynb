{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VvfOR5Qr3yDZ"
   },
   "source": [
    "#### Let's embed the data for the tag \"input_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDXoZ7h3o7a2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_CklmUL35at"
   },
   "outputs": [],
   "source": [
    "KK_PATH = './'\n",
    "# DATASET = 'code_blocks_tag_io.csv'\n",
    "DATASET = 'chunks_30.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "uNMxMypsx63n",
    "outputId": "36fdf85e-bfd4-4376-dd7f-3caa38663b21"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(KK_PATH + 'code_blocks.csv', sep='\\t')\n",
    "# df = df.dropna()\n",
    "# df = df.drop_duplicates()\n",
    "# df = df.reset_index(drop=True)\n",
    "# df['code_block_length'] = np.zeros(len(df))\n",
    "# for i in range(len(df)):\n",
    "#     df['code_block_length'][i] = len(df['code_block'][i])\n",
    "#     print(str(i)+'\\r', end='')\n",
    "# df = df.drop(df[df['code_block_length'] > 512].index)\n",
    "# df.shape\n",
    "# df.to_csv(KK_PATH + 'code_blocks_prepared.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "cvyM07BJsvwg",
    "outputId": "1cbe1cd9-6d97-44d4-b0d8-c00b1e6e9a78"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(KK_PATH + 'code_blocks_prepared.csv', sep='\\t')\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(KK_PATH + DATASET, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41055, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordListToFreqDict(wordlist):\n",
    "    def sortFreqDict(freqdict):\n",
    "        aux = [(freqdict[key], key) for key in freqdict]\n",
    "        aux.sort()\n",
    "        aux.reverse()\n",
    "        return aux\n",
    "    wordfreq = [wordlist.count(p) for p in wordlist]\n",
    "    return sortFreqDict(dict(list(zip(wordlist,wordfreq))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# wordListToFreqDict(df.code.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# nl2ml = pd.read_csv(KK_PATH + 'nl2ml.csv')\n",
    "# nl2ml = nl2ml.rename({'':'code_block', '':'method_tag'})\n",
    "# nl2ml_vis = nl2ml[nl2ml['method_tag'] == 'Visualization']\n",
    "# tokens_visualization = wordListToFreqDict(nl2ml_vis.code_block.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8DdGpT3GwvWo",
    "outputId": "14357c6e-c7c9-4572-a157-c166a2f02bb8"
   },
   "outputs": [],
   "source": [
    "def tokens_search(df, tokens, new_column_name):\n",
    "    df[new_column_name] = 0\n",
    "    for i in range(len(df)):\n",
    "        percents = str(round(100*i/len(df),1))\n",
    "        print(percents + '%\\r', end='')\n",
    "        row = df['code'][i]\n",
    "        for token in tokens:\n",
    "            result = re.search(token, row)\n",
    "            if result!=None:\n",
    "                df[new_column_name][i] = 1\n",
    "                break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1VhsSVhWj1Wx"
   },
   "outputs": [],
   "source": [
    "# TAG: input_output\n",
    "tokens_io = ['read', 'csv' , 'sql' , 'json' , 'png' , 'jpg' ,\n",
    "          'tsv' , 'write' , 'open' , 'print' , 'output' ,\n",
    "          'stdin' , 'stdout' , 'path' , 'dir'\n",
    "#            , 'import'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.1%\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = tokens_search(df, tokens_io, 'tag_import_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(KK_PATH + 'chunks_30_tag_io.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TAG: input_output\n",
    "# tokens_visualization = ['read', 'csv' , 'sql' , 'json' , 'png' , 'jpg' ,\n",
    "#           'tsv' , 'write' , 'open' , 'print' , 'output' ,\n",
    "#           'stdin' , 'stdout' , 'path' , 'dir'\n",
    "# #            , 'import'\n",
    "#           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df = tokens_search(df, tokens_visualization, 'tag_visualization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
