{"cells":[{"cell_type":"markdown","source":["## TF-IDF + Log Reg\n","### Training Pipeline"],"metadata":{"colab_type":"text","id":"lbCPRMjSjxAD","cell_id":"a6f0a381-315e-4fc1-b875-94f7e237e29e"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"155231e4-e37c-4dcf-998b-4890ae38ad71"},"source":["# !pip install dagshub"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{},"colab_type":"code","id":"YBkPvqU1iJMY","cell_id":"195e66df-de66-4b91-b39c-f04452675145"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.stats\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import *\n","\n","import dagshub\n","import pickle"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"5dfb02ba-2c84-4d2c-85f1-15f69184fa30"},"source":["def load_corpus(DATASET_PATH, CODE_COLUMN):\n","    df = pd.read_csv(DATASET_PATH, encoding='utf-8', comment='#', sep='\\t')#, quoting=csv.QUOTE_NONE, error_bad_lines=False)#, sep=','\n","    print(df.head())\n","    corpus = df[CODE_COLUMN]\n","    test_size = 0.1\n","    test_rows = round(df.shape[0]*test_size)\n","    train_rows = df.shape[0] - test_rows\n","    train_corpus = df[CODE_COLUMN][0:test_rows]\n","    test_corpus = df[CODE_COLUMN][train_rows:]\n","    return df, corpus"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"colab_type":"code","id":"rkZxucYdjxAd","outputId":"80421fe6-ac85-496a-fa5e-064c917120b5","cell_id":"fa13f41c-1a25-4e14-a575-564bb1fe77cc"},"source":["def tfidf_transform(corpus, tfidf_params, TFIDF_DIR):\n","#     tfidf = TfidfVectorizer(min_df=5\n","#                             , max_df = 0.3\n","#                             , ngram_range = (1,2)\n","#                             , smooth_idf = True\n","#                            )\n","    # tfidf = TfidfVectorizer(tfidf_params)\n","    # features = tfidf.fit_transform(corpus)\n","    tfidf = pickle.load(open(TFIDF_DIR, 'rb'))\n","    features = tfidf.transform(corpus)\n","    return features"],"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def tfidf_fit_transform(code_blocks, tfidf_params, TFIDF_DIR):\n","    tfidf = TfidfVectorizer(tfidf_params)\n","    tfidf = tfidf.fit(code_blocks)\n","    pickle.dump(tfidf, open(TFIDF_DIR, \"wb\"))\n","    code_blocks_tfidf = tfidf.transform(code_blocks)\n","    return code_blocks_tfidf"]},{"cell_type":"code","metadata":{"colab":{},"colab_type":"code","id":"-clcrT5-jxAl","scrolled":true,"cell_id":"3041592d-1fa0-44c3-93b5-3a0683be87e1"},"source":["def logreg_evaluate(df, code_blocks, TAG_TO_PREDICT):\n","    code_blocks_tfidf = tfidf_fit_transform(code_blocks, tfidf_params, TFIDF_DIR)\n","    X_train, X_test, y_train, y_test = train_test_split(code_blocks_tfidf, df[TAG_TO_PREDICT], test_size=0.25)\n","    clf = LogisticRegression(random_state=421).fit(X_train, y_train)\n","    # clf.fit(X_train, y_train)\n","    print(\"saving the model\")\n","    pickle.dump(clf, open(MODEL_DIR, 'wb'))\n","    y_pred = clf.predict(X_test)\n","    accuracy = clf.score(X_test, y_test)\n","    f1 = f1_score(y_pred, y_test)\n","    print(f'Mean Accuracy {round(accuracy*100, 2)}%')\n","    print(f'F1-score {round(f1*100, 2)}%')\n","    errors = y_test - y_pred\n","    plt.hist(errors)\n","    plot_precision_recall_curve(clf, X_test, y_test)\n","    plot_confusion_matrix(clf, X_test, y_test, values_format='d')\n","    def mean_confidence_interval(data, confidence=0.95):\n","        a = 1.0 * np.array(data)\n","        n = len(a)\n","        m, se = np.mean(a), scipy.stats.sem(a)\n","        h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n","        return m, m-h, m+h\n","    conf_interval = mean_confidence_interval(errors, 0.95)\n","    print(conf_interval)\n","    metrics = {'test_accuracy': accuracy\n","               , 'test_f1_score': f1}\n","    return metrics"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"42e2ba63-38e5-444d-a9f3-0f26776f3b63"},"source":["def get_predictions(X, y, TAG_TO_PREDICT, MODEL_DIR):\r\n","    clf = pickle.load(open(MODEL_DIR, 'rb'))\r\n","    # result = loaded_model.score(X, y)\r\n","    y_pred = clf.predict(X)\r\n","    accuracy = accuracy_score(y_pred, y)\r\n","    f1 = f1_score(y_pred, y, average='weighted')\r\n","    print(f'Mean Accuracy {round(accuracy*100, 2)}%')\r\n","    print(f'F1-score {round(f1*100, 2)}%')\r\n","    errors = y - y_pred\r\n","    plt.hist(errors)\r\n","    plot_precision_recall_curve(clf, X, y)\r\n","    plot_confusion_matrix(clf, X, y, values_format='d')\r\n","    def mean_confidence_interval(data, confidence=0.95):\r\n","        a = 1.0 * np.array(data)\r\n","        n = len(a)\r\n","        m, se = np.mean(a), scipy.stats.sem(a)\r\n","        h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\r\n","        return m, m-h, m+h\r\n","    conf_interval = mean_confidence_interval(errors, 0.95)\r\n","    print(conf_interval)\r\n","    metrics = {'test_accuracy': accuracy\r\n","               , 'test_f1_score': f1}\r\n","    return metrics"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Evaluation"]},{"cell_type":"code","metadata":{"colab":{},"colab_type":"code","id":"d1rIH7pBtjFq","cell_id":"7dc1bcd5-fe3e-49f8-8211-62d7f8ddf438","output_cleared":false,"tags":[]},"source":["# if __name__ == '__main__':\n","#     DATASET_PATH = './data/code_blocks_regex_graph_v2.1.csv'\n","#     MODEL_DIR = './models/logreg_regex_graph_v2.1.sav'\n","#     TFIDF_DIR = './models/tfidf_logreg_graph_v2.1.pickle'\n","#     CODE_COLUMN = 'code_block'\n","#     TAG_TO_PREDICT = 'preprocessing'\n","#     SCRIPT_DIR = 'logreg_classifier.ipynb'\n","\n","#     df, code_blocks = load_corpus(DATASET_PATH, CODE_COLUMN)\n","#     nrows = df.shape[0]\n","#     print(\"loaded\")\n","#     tfidf_params = {'min_df': 5\n","#                     , 'max_df': 0.3\n","#                     , 'smooth_idf': True}\n","#     data_meta = {'DATASET_PATH': DATASET_PATH\n","#                 ,'nrows': nrows\n","#                 ,'label': TAG_TO_PREDICT\n","#                 ,'model': MODEL_DIR\n","#                 ,'script_dir': SCRIPT_DIR}\n","#     print(\"tfidf-ed\")\n","#     with dagshub.dagshub_logger() as logger:\n","#         metrics = logreg_evaluate(df, code_blocks, TAG_TO_PREDICT)\n","#         # metrics = get_predictions(features, df[TAG_TO_PREDICT], TAG_TO_PREDICT, MODEL_DIR)\n","#         logger.log_hyperparams(data_meta)\n","#         logger.log_hyperparams(tfidf_params)\n","#         logger.log_metrics(metrics)\n","#     print(\"finished\")"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Validation (different chunk_sizes)"]},{"cell_type":"code","execution_count":8,"metadata":{"tags":[]},"outputs":[],"source":["# if __name__ == '__main__':\n","#     all_metrics = []\n","#     chunk_sizes = [5, 10, 15, 20, 25, 30, 40]\n","#     for i in chunk_sizes:\n","#         DATASET_PATH = './data/chunks_{}_validate.csv'.format(i)\n","#         MODEL_DIR = './models/logreg_regex_graph_v2.1.sav'\n","#         TFIDF_DIR = './models/tfidf_logreg_graph_v2.1.pickle'\n","#         CODE_COLUMN = 'code'\n","#         TAG_TO_PREDICT = 'tag'\n","#         df, corpus = load_corpus(DATASET_PATH, CODE_COLUMN)\n","#         nrows = df.shape[0]\n","#         print(\"loaded\")\n","#         params = {'min_df': 5\n","#                 , 'max_df': 0.3\n","#                 , 'smooth_idf': True}\n","#         data_meta = {'DATASET_PATH': DATASET_PATH\n","#                     ,'nrows': nrows\n","#                     ,'label': TAG_TO_PREDICT\n","#                     ,'model': 'Logistic Regression'}\n","#         features = tfidf_transform(corpus, params, TFIDF_DIR)\n","#         print(\"tfidf-ed\")\n","#         with dagshub.dagshub_logger() as logger:\n","#             # metrics = logreg_evaluate(df, features, TAG_TO_PREDICT)\n","#             metrics = get_predictions(features, df[TAG_TO_PREDICT], TAG_TO_PREDICT, MODEL_DIR)\n","#             all_metrics.append(metrics)\n","#             logger.log_hyperparams(data_meta)\n","#             logger.log_hyperparams(params)\n","#             logger.log_metrics(metrics)\n","#         print(\"finished\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# all_acc = [all_metrics[i]['test_accuracy'] for i in range(len(all_metrics))]\n","# all_f1 = [all_metrics[i]['test_f1_score'] for i in range(len(all_metrics))]\n","# plt.scatter(chunk_sizes, all_acc)\n","# plt.scatter(chunk_sizes, all_f1)"]},{"cell_type":"markdown","metadata":{},"source":["## Log Reg Interpretation"]},{"cell_type":"code","execution_count":10,"metadata":{"tags":[]},"outputs":[],"source":["# def analyze_predictions(X, y, TAG_TO_PREDICT, MODEL_DIR):\n","#     clf = pickle.load(open(MODEL_DIR, 'rb'))\n","#     # result = loaded_model.score(X, y)\n","#     y_pred = clf.predict(X)\n","#     accuracy = accuracy_score(y_pred, y)\n","#     f1 = f1_score(y_pred, y, average='weighted')\n","#     print(f'Mean Accuracy {round(accuracy*100, 2)}%')\n","#     print(f'F1-score {round(f1*100, 2)}%')\n","#     errors = y - y_pred\n","#     plt.hist(errors)\n","#     plot_precision_recall_curve(clf, X, y)\n","#     plot_confusion_matrix(clf, X, y, values_format='d')\n","#     def mean_confidence_interval(data, confidence=0.95):\n","#         a = 1.0 * np.array(data)\n","#         n = len(a)\n","#         m, se = np.mean(a), scipy.stats.sem(a)\n","#         h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n","#         return m, m-h, m+h\n","#     conf_interval = mean_confidence_interval(errors, 0.95)\n","#     print(conf_interval)\n","#     metrics = {'test_accuracy': accuracy\n","#                , 'test_f1_score': f1}\n","#     return X, y, y_pred\n","# if __name__ == '__main__':\n","#     DATASET_PATH = './data/chunks_10_validate.csv'\n","#     MODEL_DIR = './models/logreg_regex_graph_v2.sav'\n","#     TFIDF_DIR = './models/tfidf_logreg_graph_v2.pickle'\n","#     CODE_COLUMN = 'code'\n","#     TAG_TO_PREDICT = 'tag'\n","#     df, corpus = load_corpus(DATASET_PATH, CODE_COLUMN)\n","#     nrows = df.shape[0]\n","#     print(\"loaded\")\n","#     params = {'min_df': 5\n","#              , 'max_df': 0.3\n","#              , 'smooth_idf': True}\n","#     data_meta = {'DATASET_PATH': DATASET_PATH\n","#                 ,'nrows': nrows\n","#                 ,'label': TAG_TO_PREDICT\n","#                 ,'model': 'Logistic Regression'}\n","#     features = tfidf_transform(corpus, params, TFIDF_DIR)\n","#     print(\"tfidf-ed\")\n","#     X, y, y_pred = analyze_predictions(features, df[TAG_TO_PREDICT], TAG_TO_PREDICT, MODEL_DIR)\n","#     print(\"finished\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# pd.set_option('max_colwidth', 500)\n","# pd.set_option('max_rows', 500)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# ## False Positives (preprocessing y/n)\n","# corpus[(y_pred-y)==-1].reset_index(drop=True)[:]"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["from operator import itemgetter\n","def show_most_informative_features(model, vectorizer=None, text=None, n=20):\n","    \"\"\"\n","    Extract the vectorizer and the classifier from the pipeline\n","    \"\"\"\n","    if vectorizer is None:\n","        vectorizer = model.named_steps['vectorizer']\n","    else:\n","        text = vectorizer.transform([text])\n","\n","    classifier = model#.named_steps['classifier']\n","    feat_names = vectorizer.get_feature_names()\n","\n","    # Check to make sure that we can perform this computation\n","    if not hasattr(classifier, 'coef_'):\n","        raise TypeError(\n","            \"Cannot compute most informative features on {}.\".format(\n","                classifier.__class__.__name__\n","            )\n","        )    \n","\n","    # Otherwise simply use the coefficients\n","    tvec = classifier.coef_\n","\n","    # Zip the feature names with the coefs and sort   \n","    coefs = sorted(\n","        zip(tvec[0], feat_names),\n","        key=itemgetter(0), reverse=True\n","    )\n","\n","    # Get the top n and bottom n coef, name pairs\n","    topn  = zip(coefs[:n], coefs[:-(n+1):-1])\n","\n","    # Create the output string to return\n","    output = []\n","    # output = pd.DataFrame()\n","    # If text, add the predicted value to the output.\n","    if text is not None:\n","        # output.append(\"\\\"{}\\\"\".format(text))\n","        # output.append(\n","        #     \"Classified as: {}\".format(model.predict(text))\n","        # )\n","        # output.append(\"\")\n","        print(\"Classified as: {}\".format(model.predict(text)))\n","    # Create two columns with most negative and most positive features.\n","\n","    for (cp, fnp), (cn, fnn) in topn:\n","        print(cp, fnp, cn, fnn)\n","        output.append(\n","            \"{:0.2f}{: >15}    {:0.2f}{: >15}\".format(\n","                cp, fnp, cn, fnn\n","            )\n","        )\n","\n","    return \"\\n\".join(output)"]},{"cell_type":"code","execution_count":36,"metadata":{"tags":["outputPrepend"]},"outputs":[{"output_type":"stream","name":"stdout","text":"2.3542671378198365 preprocess_data -0.8115179934301682 optim\n2.342591875572756 converters -0.8112821672026299 revenue\n2.3088188325493317 normalize_train_df -0.8112814693317606 max_depth\n2.3080509442376456 reset_index -0.8095950170915466 cmap\n2.305053061122067 ps -0.8047111148717763 dataframe\n2.260900244373241 iowa_model -0.8046399704184807 thresh\n2.2451201005523447 nthread -0.7962325925645427 imputed_x_train\n2.240481402449969 count_vectorizer -0.794739429361593 test_index\n2.2296438526009816 x_test_scale -0.7931005736137324 rf\n2.2290998691768245 data_new_scaled -0.7907898954797188 datetimeindex\n2.211130640681788 224 -0.7898133774608898 isnull\n2.205590909029939 preprocessed -0.7896623174046836 datasets\n2.2036217412115833 mask -0.7896136899535711 12\n2.195748737030879 payload -0.7881389924885668 scatterplot\n2.1953703862459375 fit_intercept -0.7876030358874339 feature_importances_\n2.1929268336200267 q0 -0.7845745506246161 num_words\n2.1868158331436174 grp -0.7841018450234203 to_categorical\n2.1769343521354823 io -0.7835348043474181 n_folds\n2.172696754538191 chart -0.7813503866555821 growth\n2.172503811337338 sentence -0.7812362216093486 mark\n2.1699252352617333 converter -0.7801362908178624 set_xticks\n2.1698644520803203 scaleddf -0.7799362258846564 showlegend\n2.1654522442667505 and -0.7791256313196375 log_y\n2.1629130915798624 vect -0.7785764741213399 r2_score\n2.15411217461026 none -0.7748608380763369 wv\n2.147673404107054 d_df_merged -0.7735705534009487 num_epochs\n2.135944985577588 zfill -0.7708836423956692 step_4\n2.133722100443637 matched_df -0.7707051676296445 sqrt\n2.1283353893806516 train_prep -0.7706420187249021 learner\n2.1247610195700704 cfg -0.7700960358694574 max_columns\n2.123922962857874 enc -0.7686682271648592 sepal\n2.1176700246270137 gensim -0.768517477651215 filenames\n2.1063060678024983 loc -0.7672002847982899 oob_score\n2.1048856473717596 atom_idx -0.7656353426666392 death\n2.09218157026894 convert_tokens_to_ids -0.7655000704476169 inference_albert_and_display_results\n2.079080257102631 data_concatenado -0.7652411527296794 findall\n2.067545663019046 portland -0.7639134589914678 mnist\n2.059525187225378 pgm -0.763775987388881 num_leaves\n2.0588143056995576 albu -0.7595920917023669 rmse\n2.033033785613801 risk_factor_normalized -0.7581901999071482 imputed_x_valid\n2.024097860109879 snowballstemmer -0.7571539770864198 pred_list\n2.0177409398869326 steps -0.7557313053451068 histogram\n2.008311927265584 255 -0.7556405144981893 max_rows\n2.0074563160807757 window -0.7551795750443718 session\n2.005104460176158 current_batch -0.7537534879344291 compose\n1.9983346063327134 if -0.7515872606705809 df_traintest8\n1.9885037915538852 upsample -0.7507005855813701 marker_color\n1.988370543120733 false -0.7503975731123654 train\n1.9705816703305403 x_scale -0.7500900589888508 __version__\n1.9689581944991388 viridis -0.7498934204085352 totensor\n1.9649775672004866 range_color -0.7485232621223562 lg\n1.9602513661080463 target_size -0.7455667596046877 isna\n1.945736024992844 tight -0.7419592245320235 dados\n1.9455688316024833 y_scaler -0.7411633684335402 accuracy_score\n1.9440458510111955 changepoint_prior_scale -0.7403668153413946 customers\n1.934257371525402 json -0.7392345593674433 number\n1.9240920058188316 layout -0.7379211536127402 vocab\n1.9215324758244838 min_max_scaler -0.7377838888639594 domain\n1.9188378353032671 school_reg_merged -0.7360671615097001 contours\n1.9183178129395295 atoms -0.7358904312657507 regex\n1.9164908701939225 rgb -0.7353028111844709 test_ds\n1.908052484205603 df_panel -0.7339372880293678 ascending\n1.890684206099209 config -0.7315752730222598 step_2\n1.8895476755881986 hm -0.7296467606905649 variety\n1.8871201989962736 day_wise -0.7283681223295042 models\n1.8838153615501934 make_pipeline -0.72826088384596 latest_data\n1.8789904274065163 isin -0.7265914503035179 pass\n1.8741616300458055 scaled_test_x -0.7248103484567872 20\n1.8506330001601374 dst_non_crop -0.7244783180021682 13\n1.8450888364683473 px -0.723651316957131 regplot\n1.8444561827385526 feature_range -0.719987021516254 yy\n1.8340739116247355 function -0.719393079259467 spines\n1.8313192799600166 train_purch_merged -0.717800680884044 from_pretrained\n1.8269712583724749 teamid -0.7173103154296365 lang\n1.813791854883856 preprocessed_documents -0.7164160403432963 criterion\n1.81289260053446 preprocessed_reviews -0.7157583917197549 plot_categorical_feature\n1.8109268988519203 new_history -0.7156686721159546 dict_\n1.8105924952998274 int -0.7146608494853925 procs\n1.7996039816312808 set_context -0.7134563558065145 categorical_features\n1.7993579416143395 scaling -0.7121394414888551 background_gradient\n1.7949457240726088 columntransformer -0.7116919426808752 classification_report\n1.7924089667086642 tfidf_vectorizer -0.70881682702096 latentdirichletallocation\n1.7917303442249815 ignore_index -0.7006342779932702 bagging_seed\n1.7914010512135563 country_wise -0.6998439780743505 df_covid19\n1.789101692029526 max_df -0.6909222116450783 defaultdict\n1.7855652972115632 words_freq -0.6900288262336235 final_x_valid\n1.7854680000362917 hidden -0.6898624831864602 x_train_new\n1.778994758045541 cr -0.6894375089381062 twitter_data\n1.775106566110624 lstm_predictions_scaled -0.6893883728084901 actual\n1.7730604634980605 crop_size -0.6890953339262154 pairwise\n1.7683117701277988 gridsearchcv -0.6881409730563605 lines\n1.7680680304451435 np -0.6881158666087307 create_model\n1.7642249653021922 train_samples_count -0.6868633472368318 submission_df\n1.761942114467211 shift -0.6861382617152603 y_train_pred_final\n1.761057903449548 outer -0.6844435281956276 expand\n1.7594598533281502 scaled_inputs -0.6836853357776171 gleason_score\n1.7589993311177439 py -0.6826598523813984 final_imputer\n1.7517465977896545 weight_average_score_hybrid -0.6819225340053874 final_x_train\n1.7485315886161787 component -0.6817301362999681 mylist\n1.7420589477607316 val_x -0.6811113930692718 textfont\n1.7393913571360506 img_size -0.6747715467446834 gaussiannb\n1.732016819459811 y_validation -0.6742345243044815 add_legend\n1.7286631420266145 x_train_scale -0.6692115149958947 edgecolor\n1.725684315573953 margin -0.6690776683390862 max_colwidth\n1.7216166905968466 generation1 -0.6687189069819367 pclass\n1.7212882174424948 my_generator -0.6678519968020963 pred_test_y\n1.721259151084333 max_seq_length -0.6676022697169007 color_bgr2gray\n1.711657444308851 drug -0.6650298590728221 circle\n1.7092516268936393 annot_kws -0.6625001132331242 categorical_feature\n1.708919336381565 self -0.6622568631865529 test_imgs\n1.7080204582637533 scale_factor -0.6612236824736111 add_to\n1.70459586076109 applications -0.6592118970334279 barmode\n1.7003840395157301 min_child_weight -0.6577321032849393 fi\n1.700009609397696 time_start -0.6558891961283297 x_reduced\n1.699357554799572 preprocess_text -0.6558427072401456 run\n1.6991356950128413 feature_columns -0.6550175981078515 salary\n1.6934522368635263 keras -0.6542511314873793 only_covid19\n1.6907384450145444 re -0.6528957628283529 stacked\n1.6892324328509671 df_benchmark_panel -0.6519151169721238 plot_bgcolor\n1.6882139036217414 totals -0.6515870303053023 accuracy\n1.6877707075208368 max_len -0.6507458919916949 y_prediction\n1.6832420454530106 combined_train_test -0.6502826857596986 coronavirus\n1.6821606873786616 bow -0.649291200441418 pink\n1.6807989899235272 token_ids -0.648812080637706 reviews\n1.676297841892131 cmap1 -0.6484265053277855 test_preds\n1.6755217255980919 tokens -0.6467335988206989 val_loss\n1.6738941971467103 df_aux -0.6458805411074775 hole\n1.6702051657018226 molecule_name -0.6444691627910865 adjusted_dates\n1.6699955018566564 ystart -0.6443232501184322 lens\n1.6669011523199093 val_mae -0.6439500743746277 requires_grad\n1.6651646649184388 with -0.6438457833104785 365\n1.6625364067001673 day_ -0.6423746439930462 sm\n1.658693488168159 rainbow -0.6382267347405906 species\n1.6573687195802793 techindicator -0.6350805889956131 factorplot\n1.6564349696939589 sample_augmentations -0.6346570793647764 input_path\n1.6439289006872406 unstack -0.6345777210929934 os\n1.6418206307697036 tweet -0.6341405251564348 is\n1.6356794813435678 minneighbors -0.6304700125055834 weekly_sales\n1.6356794813435678 scalefactor -0.6289298966490764 y_pred_test\n1.633292320926986 emergency_vehicle -0.6254214046767149 covariate_shift\n1.632084726176994 minmax_scale -0.6252628891696023 x_new\n1.6310435328999566 review -0.6219688172500072 checkpoint\n1.6302163335119328 test_x_scaled -0.6203189692601914 xlsx\n1.6263674633857592 legendary_generation3 -0.620231685151828 covariate\n1.6258013234630835 scaled_train_data -0.6198981978482894 infer_datetime_format\n1.620710772673855 unscaled_inputs -0.6196240338020468 df5\n1.6198341710099238 data_preprocessed -0.6185078997552972 spam\n1.605065104185715 unnormalize_transform -0.6180146213780565 encrypted\n1.6046073705678456 tokens_a -0.61652064304402 train_sizes\n1.6043052115637724 onehot -0.615387165006112 embed\n1.6029497954804601 bubbleplot -0.6147746473118293 dot\n1.6025599387017366 regr_dict -0.6147603068647393 temp_dict\n1.5998570799701008 roi -0.6142314685883867 case\n1.5995574882187609 reshape -0.6141957625916867 df_iris\n1.5963836843158659 prediction_arima_log -0.6140797107933826 matcher\n1.5945288597691358 lr_best_scaled -0.6129647916472423 datewise\n1.5944049601136896 mlp_train -0.6123163680543479 xlabel\n1.594109952723899 tmp -0.6110965229742928 min_samples_split\n1.5939750103146326 ascii -0.6098601955835973 xm\n1.593471615345188 pc -0.6096625711786846 param_distributions\n1.5928799707489933 512 -0.6083172629012349 infected\n1.5906770313434082 sklearn -0.6082591068777423 df_can\n1.5900103042316809 indexes -0.6076373004418392 aspect\n1.5858409034982293 conv1d -0.6066221992343922 titanic_train\n1.5851867427278876 my_pipeline -0.6064573409618192 entry\n1.5800156661305036 scaled_testing -0.604631080951878 kde\n1.5794377267799093 astype -0.6041859105932662 53\n1.578925172175869 scalar_coupling_constant -0.6038703008926416 mydata\n1.577970148427352 x_merged -0.6031612196069447 225\n1.5775397670575908 marker -0.6017374471325729 lengths\n1.5774636357082847 plot_with_augmentation -0.601720985068361 df_credit\n1.576055255579106 globalaveragepooling1d -0.601539074657041 are\n1.5713222286067037 class_mode -0.6012572577018358 corr_matrix\n1.568387994344904 image_size -0.5975384602999386 nn\n1.567393986421523 suffixes -0.5974200448592764 plot_numerical\n1.5668630960167003 cropped -0.5972497849168353 test_raw\n1.565761650544833 train2 -0.5969051417545487 forecast\n1.564913991828813 text_preprocessing -0.5967011752797139 parse_dates\n1.5599986715989853 motorcycle -0.5962556975446393 there\n1.5588900150550784 uint8 -0.5960765157312775 grid_search\n1.5583711843122972 runs -0.5956613572582801 monitor\n1.5574081222432492 df_temp -0.594862097744751 extraction\n1.554218337768511 lowercase -0.5939770982558189 229\n1.5523653868039053 ordinalencoder -0.5931831434861227 stopword\n1.5504787962360254 concated -0.5913018190963019 cache\n1.547890630707058 into -0.591152919234849 todays_date\n1.5474400981380043 val_predictions -0.5905796578729254 fgvc7\n1.5441348947052214 show_wordcloud -0.590397160552865 rmsle\n1.5434020138903384 df_merged2 -0.5899117141797737 logarithmic\n1.53591358902466 risk_with_inj -0.588461459806547 input\n1.5330356427234104 subsample -0.5884116999788941 correlation\n1.5316662711295324 vocab_file -0.5875776648573806 gstatic\n1.5293124212791218 val_df -0.5861860372729498 patience\n1.5278372499134294 df_ -0.585966909187559 average\n1.5258839007443596 preprocessing_function -0.5847415345554221 public_test\n1.5256287576946983 load_img -0.5845628359562948 df_train\n1.5255507901526826 timesteps -0.5839638417052069 traces\n1.5240104035095103 cluster -0.5838447707100209 meta_data\n1.522745924777969 cropping -0.5837208510733641 sizes\n1.5218725944470013 resize_image -0.5834979342857778 json_file\n1.521731789947677 color_mode -0.5832578661985574 kf\n1.5216615585616373 site_id -0.5828319500658807 data_df\n1.5206013379618148 context -0.5824665920371971 days_of_pace_keep\n1.5165315700162771 df_output -0.5823278667846022 xaxis_title\n1.5163881177829701 scrollzoom -0.5818964697160806 best_alpha\n1.5150093158483968 df_path -0.5810144615000636 freq_dict\n1.5089141427971202 method -0.5809162168413073 from_dict\n1.5080366662114693 0f -0.5806741846477501 stripplot\n1.5067656444969297 scales -0.580510937702723 model_ft\n1.5024770948983979 movies_scaled -0.5800492273713171 tbn0\n1.5018177432209503 statesdf -0.5795369015710383 fillmissing\n1.5014011421605844 hover_name -0.5780448195911214 components_\n1.4996437606561068 x_column -0.5739899809062151 transformermixin\n1.4987359081851497 set_xscale -0.573124713566408 df_tr\n1.4962333936976746 train3 -0.5722423013513299 wheat\n1.4954649834006148 datashifting -0.5718785378969989 ex\n1.4953546884981082 convert_dict -0.5717127030140785 samplewise_std_normalization\n1.4940856845211152 pipe -0.5716177019018562 iris\n1.4935426821112268 retinopathy -0.5702092286149902 club\n1.4922715975988117 crops_dir -0.5701528904616538 append_trace\n1.4876572138368835 variables -0.5699265320090058 daterep\n1.4855625894720876 sent -0.5695040331360494 zomato\n1.4811063151633403 y_log_normalized -0.569224234604657 tight_layout\n1.4808732647461582 test_linear_pred -0.5688903472485429 485\n1.4804244953689716 split_text -0.5688551258574198 embed_size\n1.478683491851338 preprocessed_df -0.5659082632767503 categorify\n1.4779467412834184 ft -0.565051227630033 tbn\n1.4769998510103053 treemap -0.5647020419393696 delimiter\n1.4756136630395487 str -0.5645271639984315 rfc\n1.4744752403807417 train_clean -0.564313940753846 check_output\n1.4742253488501937 sort_index -0.5642068835918751 bigquery\n1.4688952682272691 maxlen -0.5642017296635511 mean_encoding\n1.4674586459393877 tokenized_text -0.5629947964659434 to_drop\n1.4668464235986387 merged_test_df -0.5593203177101846 800\n1.4653230956604693 lightgbm -0.5589208597901126 seri\n1.4622670730247098 df_normalized -0.5583633241409154 rate\n1.4606082188661222 convertnum -0.558352131677011 cut\n1.4604556730100098 matchtype -0.55731553761306 tarih\n1.4598683447145084 scaler_x -0.5557975091029355 input_word_ids\n1.4596940052692562 bert_encode -0.5554348167284177 performance\n1.45542685337433 tests_merged_notna -0.555014897275043 va\n1.4549511089484497 country -0.5543647459389006 bottom\n1.4539492148089799 comment_text -0.5542692461700716 t0\n1.4510535293276137 correlation_train -0.5538273913702281 displacy\n1.4507874506989047 face -0.5534227437055901 weights_lambda\n1.4499625289109825 layout_coloraxis_showscale -0.5533033137766048 sampler\n1.4494942716099937 directory -0.5533002312513396 smoker\n1.4450514571121675 for -0.5530639969983889 thresholds\n1.4447365420146008 iaa -0.5528755440337236 logy\n1.4415629861902266 logging -0.5525431506955261 sample\n1.4409135275052283 testpredictplot -0.5515437930914644 environ\n1.439739556913126 categorical_transformer -0.5504811195888433 regression\n1.4376821367029937 33 -0.5503806456364476 embeddings_index\n1.437679839132114 scale_data -0.5499360187064956 w1\n1.4369090723108096 data_d -0.5496471367606532 quality\n1.4366546634259163 fast_encode -0.549557234768446 df3\n1.4337958105761919 preprocessed_comments_test -0.5494526981694161 cosine_similarity\n1.433684145333896 scaled_train_x -0.5493818743944635 file_list\n1.433256745850397 names -0.5492799028038008 listed_in\n1.4329151267723315 train_val_merge -0.5481847728098198 callback\n1.4326497217156786 urine -0.5453013497680771 df_us\n1.4325180366912937 missing_data -0.5451566007130195 select\n1.4308932166130328 submissions -0.5449587383902638 sig_clf\n1.430350602569841 data1_scaled -0.5442599643077579 samplewise_center\n1.4274921948422583 pixels -0.5441341450328258 skew\n1.4254442229428224 num_vars -0.5438908074213569 margins\n1.4238984404543507 grid_df -0.5438863864640215 spectrograms\n1.4198518391693864 size_column -0.543875958815585 imread\n1.4196088357199035 convert_to_num -0.5435361017866769 all_df\n1.4188982515675435 x_num -0.5425537823395488 cased\n1.4184532917706711 lemmatization -0.5422971168730237 yaxis_title\n1.4176115842076125 180 -0.5419875589455503 collapsed\n1.415358661042461 roberta_path -0.5413524428267703 sns\n1.4150218813725717 tmp_df -0.5410969882620303 yhat\n1.4139988953433 sentence_embeddings -0.5409042230890407 v2\n1.411473775685651 uniques -0.5407108622024664 bertwordpiecetokenizer\n1.411253833693672 scale_id -0.5404672597046422 bad\n1.411105282716877 legendary_generation1 -0.5403238906913228 18\n1.41033151460686 user_suggestion -0.5400143463874995 shops\n1.4078439417572455 expmax -0.5382295477321954 updates\n1.4070151749034916 x_valid_scaled -0.538006919227134 board\n1.4069822022274532 bs -0.5377708286029635 reported_date\n1.4065640552427139 imagenet_stats -0.5376692434862518 train_index\n1.4053858180230956 colorbar_title -0.5373691691196731 all_articles\n1.4046091680867352 date_title_count -0.5372243384698511 df_world\n1.4029230504951358 full_grouped -0.5370537230300192 visualize\n1.4013356700616033 img0 -0.5368663024286248 heart_df\n1.4011080852435733 merges_file -0.5367834908933276 status\n1.3973496602075344 test_purch_merged -0.5364742700868297 model_cv\n1.39697421793498 mergesort -0.535448577040039 rho\n1.3963131308710421 train_data_normalized -0.534550965335624 totalcharges\n1.3936935816980123 diabetic -0.5334734041428002 starts\n1.3936747404832353 one_hot_encode -0.5331258307368066 embedding_vector\n1.3927689149282532 empty -0.5328108572072041 kaggledatasets\n1.3885218302084366 t_iter -0.5327699597781557 trends\n1.3859035931934278 visualizer -0.5322268176682653 iinfo\n1.3853997942385414 toarray -0.531653080457431 n_estimators\n1.3813794557300023 y_column -0.5310151813611457 ols\n1.3793043413308403 x_full -0.5303837525988058 mexico\n1.377219409817499 pickle -0.5302619637636694 image_dir\n1.3756084098567143 missing -0.5301490158965093 chained_assignment\n1.3714715680668979 x_temp -0.529884030442128 flag\n1.3701146356012264 augmentations -0.5295631941015116 vc1\n1.3700653009744037 scaled_px -0.5291826079673302 test_vectors\n1.3691859680885128 model_features -0.5288500643071087 textposition\n1.36903732223177 bert_model_path -0.5279558446000838 frequent\n1.3676000129569372 bubble_column -0.5278064916933503 df2\n1.3600434423554237 blues -0.5272534179682633 interp\n1.3598609218089281 df_scaled_train -0.5259871266834412 gradientboostingregressor\n1.3592060142910016 deacc -0.5258522154527112 train_df_final\n1.359169686645415 scl -0.5253509748947447 k_fold\n1.3588042619159395 standard_scaler -0.5249140881969734 recorder\n1.3578173130974338 doc_id -0.5234032981602026 hint\n1.356833420179965 to_frame -0.5233097008697206 pytorch\n1.3555256901575325 total_df -0.5229642784368064 keywords\n1.3517568078249078 go -0.5229312735464497 test_ind\n1.3512909401331823 y_res_test -0.5228169266269238 encoder\n1.3476190732883762 reader -0.5225992562755347 model_1\n1.347172825225966 reason_category -0.5217229106077256 logmodel\n1.3442736705043634 usecols -0.5208739858241976 neural_network\n1.3430466055544876 preprocess_string -0.5207379536926519 ln\n1.3417729024287643 answer -0.5205080526112786 sex\n1.3415041789590987 unknown -0.5200965015379522 y_hat\n1.3399079991790146 diameter -0.5184287260221546 pred_proba\n1.3397498595270685 x_train_rescaled -0.5166579314950019 app_train\n1.3393515809735888 scale_bubble -0.516369506519963 tick_params\n1.339022649437788 preprocesser -0.5159600183544614 fpath\n1.3378447767180783 robustscaler -0.5157182653630289 sparse_categorical_crossentropy\n1.337471926215916 b64 -0.5155202814845627 x_embedded\n1.3363543613121827 y_title -0.5135065488275291 root_path\n1.336287986025452 kernel_initializer -0.5134327073069753 openslide\n1.3362437618682035 new_array -0.5124522211695897 png\n1.3346130274240335 blue_scaler -0.5107847544401788 baseestimator\n1.3332078172438162 x_title -0.5106751536981184 featurewise_std_normalization\n1.3331354504560302 api -0.5104942071340332 pull\n1.3319321476242056 mis_val_table_ren_columns -0.510464155600571 all_json\n1.331334762195487 batch_size -0.510229400006581 gtf\n1.3307362075942353 val_ix -0.5101536538555868 classifiers\n1.3281436022297803 papers_preprocessed_df -0.5093622651869183 hit_dictionary\n1.3274075641748335 update_layout -0.5080115492860714 vaccine\n"}],"source":["MODEL_DIR = './models/logreg_regex_graph_v2.1.sav'\n","TFIDF_DIR = './models/tfidf_logreg_graph_v2.1.pickle'\n","DATASET_PATH = './data/chunks_10_validate.csv'\n","CODE_COLUMN = 'code'\n","TAG_TO_PREDICT = 'tag'\n","df, corpus = load_corpus(DATASET_PATH, CODE_COLUMN)\n","interpret = show_most_informative_features(model=pickle.load(open(MODEL_DIR, 'rb')),\n","                                vectorizer=pickle.load(open(TFIDF_DIR, 'rb')),\n","                                text=corpus[5],\n","                                n = 500)\n","# with open('logreg_interpret.txt', mode='w') as f:\n","#     f.write(interpret)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":1,"metadata":{"colab":{"collapsed_sections":[],"name":"NL2ML: LogReg.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.8.5 32-bit","language":"python","name":"python_defaultSpec_1597940714992"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5-final"},"deepnote_notebook_id":"2fa6153d-52cd-43ae-af2d-05210d5785e2","deepnote_execution_queue":[]}}