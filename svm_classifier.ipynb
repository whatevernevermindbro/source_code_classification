{"cells":[{"cell_type":"code","metadata":{"cell_id":"7f699a8d-e501-4d30-8443-201f2e561d35"},"source":["import pandas as pd\n","import numpy as np\n","import pickle\n","from datetime import datetime\n","\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import KFold, GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.multiclass import OneVsRestClassifier\n","\n","import dagshub\n","\n","def load_code_blocks(DATASET_PATH, CODE_COLUMN):\n","    df = pd.read_csv(DATASET_PATH, encoding='utf-8', comment='#', sep=',')#, quoting=csv.QUOTE_NONE, error_bad_lines=False)#, sep=','\n","    print(df.head())\n","    code_blocks = df[CODE_COLUMN]\n","    # test_size = 0.1\n","    # test_rows = round(df.shape[0]*test_size)\n","    # train_rows = df.shape[0] - test_rows\n","    # train_code_blocks = df[CODE_COLUMN][0:test_rows]\n","    # test_code_blocks = df[CODE_COLUMN][train_rows:]\n","    return df, code_blocks\n","\n","def tfidf_fit_transform(code_blocks, params, TFIDF_DIR):\n","    vectorizer = TfidfVectorizer(**params)\n","    tfidf = vectorizer.fit(code_blocks)\n","    pickle.dump(tfidf, open(TFIDF_DIR, \"wb\"))\n","    print('TF-IDF model has been saved')\n","    code_blocks_tfidf = tfidf.transform(code_blocks)\n","    return code_blocks_tfidf\n","\n","def SVM_evaluate(df, code_blocks, tfidf_params, TFIDF_DIR, SVM_params):\n","    code_blocks_tfidf = tfidf_fit_transform(code_blocks, tfidf_params, TFIDF_DIR)\n","    X_train, X_test, y_train, y_test = train_test_split(code_blocks_tfidf, df[TAG_TO_PREDICT], test_size=0.3)\n","    # grid = {\"C\": [100]}\n","    # cv = KFold(n_splits=2, shuffle=True, random_state=241)\n","    model = SVC(kernel=\"linear\", random_state=241)\n","    # gs = GridSearchCV(model, grid, scoring=\"accuracy\", cv=cv, verbose=1, n_jobs=-1)\n","    # gs.fit(X_train[:25000], y_train.ravel()[:25000])\n","    # C = gs.best_params_.get('C')\n","    # model = SVC(**SVM_params)\n","    print(\"Train SVM params:\", model.get_params())\n","    n_estimators = 10\n","    clf = BaggingClassifier(model, max_samples=1.0 / n_estimators, n_estimators=n_estimators)\n","    # clf = model\n","    print(\"starting training..\")\n","    clf.fit(X_train, y_train)\n","    print(\"saving the model\")\n","    pickle.dump(clf, open(MODEL_DIR, 'wb'))\n","    print(\"predicting on the test..\")\n","    y_pred = clf.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred, average='weighted')\n","    # confus_matrix = confusion_matrix(model, X_test, y_test)\n","    metrics = {'test_accuracy': accuracy\n","            , 'test_f1_score': f1}\n","    print(metrics)\n","    return metrics"],"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# if __name__ == '__main__':\n","#     DATASET_PATH = './data/code_blocks_regex_graph_v2.1.csv'\n","#     MODEL_DIR = './models/svm_regex_{}.sav'.format('graph_v2.1')\n","#     TFIDF_DIR = './models/tfidf_svm_graph_v2.1.pickle'\n","#     CODE_COLUMN = 'code_block'\n","#     TAG_TO_PREDICT = 'preprocessing'\n","#     SCRIPT_DIR = __file__\n","    \n","#     df, code_blocks = load_code_blocks(DATASET_PATH, CODE_COLUMN)\n","#     nrows = df.shape[0]\n","#     print(\"loaded\")\n","#     tfidf_params = {'min_df': 5\n","#             , 'max_df': 0.3\n","#             , 'smooth_idf': True}\n","#     SVM_params = {'C':100\n","#             , 'kernel':\"linear\"\n","#             , 'random_state':241}\n","#     data_meta = {'DATASET_PATH': DATASET_PATH\n","#                 ,'nrows': nrows\n","#                 ,'label': TAG_TO_PREDICT\n","#                 ,'model': MODEL_DIR\n","#                 ,'source': SCRIPT_DIR}\n","\n","#     with dagshub.dagshub_logger() as logger:\n","#         print(\"evaluating..\")\n","#         metrics = SVM_evaluate(df, code_blocks, tfidf_params, TFIDF_DIR, SVM_params)\n","#         print(\"saving the results..\")\n","#         logger.log_hyperparams(data_meta)\n","#         logger.log_hyperparams(tfidf_params)\n","#         logger.log_hyperparams(SVM_params)\n","#         logger.log_metrics(metrics)\n","#     print(\"finished\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    DATASET_PATH = './data/code_blocks_regex_graph_v2.1.csv'\n","    MODEL_DIR = './models/svm_regex_{}.sav'.format('graph_v2.1')\n","    TFIDF_DIR = './models/tfidf_svm_graph_v2.1.pickle'\n","    CODE_COLUMN = 'code_block'\n","    TAG_TO_PREDICT = 'preprocessing'\n","    SCRIPT_DIR = 'svm_classifier.ipynb'\n","    clf = pickle.load(open(MODEL_DIR, 'rb'))"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["# tfidf = pickle.load(open(TFIDF_DIR, 'rb'))\n","# len(tfidf.vocabulary_)"]},{"cell_type":"code","execution_count":61,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"w =    (0, 37211)\t0.035646233761817\n  (0, 34323)\t0.030950524230484572\n  (0, 29584)\t0.035646233761817\n  (0, 26147)\t0.029679575247906122\n  (0, 24917)\t0.035646233761817\n  (0, 19800)\t0.06721916326465512\n  (0, 18078)\t0.03250528522413417\n  (0, 31751)\t0.3790859004196737\n  (0, 13342)\t0.15071739978159376\n  (0, 45380)\t0.2723816199314875\n  (0, 45377)\t0.2785312498516836\n  (0, 31798)\t0.025936232700084456\n  (0, 4482)\t0.028515522724737143\n  (0, 41031)\t0.32591415458340406\n  (0, 36801)\t0.13961101849195767\n  (0, 31696)\t0.13961101849195767\n  (0, 27633)\t0.12935753551689436\n  (0, 16699)\t0.12774161988093802\n  (0, 37329)\t0.08375070222986938\n  (0, 37311)\t0.0830840198551464\n  (0, 36534)\t0.2585720973751989\n  (0, 34463)\t0.8537643986305498\n  (0, 41406)\t0.27096391350885946\n  (0, 11954)\t0.24268623564190253\n  (0, 42145)\t0.24137468565479947\n  :\t:\n  (0, 41919)\t0.1413290554429865\n  (0, 40426)\t-0.12128050809560675\n  (0, 39987)\t0.43936220103801604\n  (0, 38565)\t-0.15207254814850366\n  (0, 38001)\t-0.13588208562448223\n  (0, 37456)\t0.31094391051828235\n  (0, 30681)\t-0.0874742954574615\n  (0, 27527)\t-0.0174303001248889\n  (0, 27081)\t-0.8532984704468206\n  (0, 25539)\t-0.40716758545939274\n  (0, 23546)\t0.8894886349266458\n  (0, 22483)\t-0.15510759471670804\n  (0, 22028)\t-0.19879350922131683\n  (0, 21693)\t-0.23675907753219136\n  (0, 19742)\t0.3231531619939074\n  (0, 16882)\t0.2550540449006558\n  (0, 15530)\t-0.07262307177522342\n  (0, 15521)\t-0.159235436799267\n  (0, 13071)\t-0.44761698234546365\n  (0, 9747)\t-0.07412096580206054\n  (0, 6667)\t0.07145576440295584\n  (0, 3875)\t0.11698117970342853\n  (0, 3800)\t0.7578202376006374\n  (0, 3740)\t-0.06442471472555167\n  (0, 2422)\t0.42768780958051156\nb =  [-1.25490341]\nIndices of support vectors =  [    0     1     6 ... 15073 15074 15075]\nSupport vectors =    (0, 2422)\t0.35863230875994884\n  (0, 3740)\t0.13363022777825856\n  (0, 3800)\t0.15235407585313285\n  (0, 3875)\t0.1563212686510791\n  (0, 6667)\t0.18794706814834297\n  (0, 9747)\t0.15669302057280782\n  (0, 13071)\t0.14765977854010656\n  (0, 15521)\t0.28391737283908225\n  (0, 15530)\t0.24521531281036776\n  (0, 16882)\t0.09159607547587693\n  (0, 19742)\t0.2129915908894499\n  (0, 21693)\t0.2121492903761799\n  (0, 22028)\t0.20938426910088795\n  (0, 22483)\t0.1711100283895451\n  (0, 23546)\t0.14101716640614959\n  (0, 25539)\t0.1394994890802689\n  (0, 27081)\t0.12295206456765388\n  (0, 27527)\t0.31580957120804243\n  (0, 30681)\t0.15175849003829037\n  (0, 37456)\t0.21539958957811822\n  (0, 38001)\t0.1525857488985414\n  (0, 38565)\t0.1716801602357053\n  (0, 39987)\t0.1936769042404887\n  (0, 40426)\t0.1678591584307765\n  (0, 41919)\t0.14833052954829545\n  :\t:\n  (4501, 36064)\t0.08649516101742254\n  (4501, 36135)\t0.017392945521574728\n  (4501, 36681)\t0.04873732022167515\n  (4501, 37211)\t0.05334704953019724\n  (4501, 38281)\t0.06800365586074665\n  (4501, 39171)\t0.06465232144407983\n  (4501, 39355)\t0.04628906542311507\n  (4501, 40396)\t0.019382362667746733\n  (4501, 40739)\t0.040476359549818236\n  (4501, 40741)\t0.03868063274494008\n  (4501, 40744)\t0.040853918683247364\n  (4501, 41287)\t0.0664397365025504\n  (4501, 41352)\t0.018391838748988476\n  (4501, 42268)\t0.044899757830376905\n  (4501, 42524)\t0.045231286927588044\n  (4501, 42671)\t0.02669530978458823\n  (4501, 42842)\t0.12811512021942334\n  (4501, 44215)\t0.02916617744935308\n  (4501, 44508)\t0.04997842746434154\n  (4501, 44761)\t0.02340522358972729\n  (4501, 44847)\t0.03893697847360804\n  (4501, 45842)\t0.06679779340113752\n  (4501, 46349)\t0.0881502799197753\n  (4501, 46401)\t0.04069930777366219\n  (4501, 48648)\t0.026403440434249015\nNumber of support vectors for each class =  [3076 1426]\nCoefficients of the support vector in the decision function =    (0, 0)\t0.11532118874437217\n  (0, 1)\t0.06145177768758603\n  (0, 2)\t0.26749765606916664\n  (0, 3)\t0.04038061944142393\n  (0, 4)\t0.11742505800490602\n  (0, 5)\t0.26823324439137586\n  (0, 6)\t0.32830430998921806\n  (0, 7)\t1.0\n  (0, 8)\t0.1161616713175741\n  (0, 9)\t0.602724809510387\n  (0, 10)\t0.5471644463915096\n  (0, 11)\t1.4159471837263824\n  (0, 12)\t1.0\n  (0, 13)\t0.029878707955190036\n  (0, 14)\t0.109136159463248\n  (0, 15)\t0.9359158577408411\n  (0, 16)\t0.2362096693439385\n  (0, 17)\t1.0\n  (0, 18)\t1.0\n  (0, 19)\t0.15943038687315803\n  (0, 20)\t0.3555452953960085\n  (0, 21)\t1.0\n  (0, 22)\t0.11291814085807231\n  (0, 23)\t0.3748915237389305\n  (0, 24)\t0.11109412741015051\n  :\t:\n  (0, 4477)\t1.0\n  (0, 4478)\t2.0\n  (0, 4479)\t1.0\n  (0, 4480)\t1.0\n  (0, 4481)\t1.0\n  (0, 4482)\t1.0\n  (0, 4483)\t1.0\n  (0, 4484)\t1.0\n  (0, 4485)\t2.0\n  (0, 4486)\t1.0\n  (0, 4487)\t1.0\n  (0, 4488)\t1.0\n  (0, 4489)\t1.0\n  (0, 4490)\t1.0\n  (0, 4491)\t1.0\n  (0, 4492)\t0.38823861957436673\n  (0, 4493)\t1.0\n  (0, 4494)\t0.7590993007606361\n  (0, 4495)\t1.0\n  (0, 4496)\t0.08925232640622634\n  (0, 4497)\t1.0\n  (0, 4498)\t1.0\n  (0, 4499)\t1.0\n  (0, 4500)\t1.0\n  (0, 4501)\t0.668195037508857\n"}],"source":["clf = clf.estimators_[0]\n","print('w = ',clf.coef_)\n","print('b = ',clf.intercept_)\n","print('Indices of support vectors = ', clf.support_)\n","print('Support vectors = ', clf.support_vectors_)\n","print('Number of support vectors for each class = ', clf.n_support_)\n","print('Coefficients of the support vector in the decision function = ', np.abs(clf.dual_coef_))"]},{"cell_type":"code","execution_count":127,"metadata":{},"outputs":[],"source":["w = clf.coef_\n","weights = w.toarray()[0]"]},{"cell_type":"code","execution_count":156,"metadata":{},"outputs":[],"source":["vocab = list(tfidf.vocabulary_.keys())\n","vocab_freq = list(tfidf.vocabulary_.values())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# interpret.to_csv('svm_interpret.csv', index=False)"]},{"cell_type":"code","execution_count":190,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"                  vocab  vocab_freq   weights\n39589     y_test_cc_lgb       48135  4.754719\n37343         y_testl11       48174  3.691251\n21676          y_values       48331  2.548121\n42649            y_val1       48302  0.913669\n41924          y_trains       48272  0.742393\n37990        y_truth_sp       48292  0.685098\n35413          yy_train       48596  0.682025\n35295      y_test_fatal       48146  0.657406\n42438        y_sel_test       48105  0.634224\n22481  yaxis_title_text       48376  0.616938","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>vocab</th>\n      <th>vocab_freq</th>\n      <th>weights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39589</th>\n      <td>y_test_cc_lgb</td>\n      <td>48135</td>\n      <td>4.754719</td>\n    </tr>\n    <tr>\n      <th>37343</th>\n      <td>y_testl11</td>\n      <td>48174</td>\n      <td>3.691251</td>\n    </tr>\n    <tr>\n      <th>21676</th>\n      <td>y_values</td>\n      <td>48331</td>\n      <td>2.548121</td>\n    </tr>\n    <tr>\n      <th>42649</th>\n      <td>y_val1</td>\n      <td>48302</td>\n      <td>0.913669</td>\n    </tr>\n    <tr>\n      <th>41924</th>\n      <td>y_trains</td>\n      <td>48272</td>\n      <td>0.742393</td>\n    </tr>\n    <tr>\n      <th>37990</th>\n      <td>y_truth_sp</td>\n      <td>48292</td>\n      <td>0.685098</td>\n    </tr>\n    <tr>\n      <th>35413</th>\n      <td>yy_train</td>\n      <td>48596</td>\n      <td>0.682025</td>\n    </tr>\n    <tr>\n      <th>35295</th>\n      <td>y_test_fatal</td>\n      <td>48146</td>\n      <td>0.657406</td>\n    </tr>\n    <tr>\n      <th>42438</th>\n      <td>y_sel_test</td>\n      <td>48105</td>\n      <td>0.634224</td>\n    </tr>\n    <tr>\n      <th>22481</th>\n      <td>yaxis_title_text</td>\n      <td>48376</td>\n      <td>0.616938</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":190}],"source":["interpret.sort_values(by='weights', ascending=False)[interpret['vocab_freq'] > 48000].head(10)"]},{"cell_type":"code","execution_count":186,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"                                vocab  vocab_freq    weights\n37343                       y_testl11       48174   3.691251\n39589                   y_test_cc_lgb       48135   4.754719\n9856                      traumatized       44062   5.444746\n9434                         trainset       43933   4.694664\n43744                 switzerland_nan       40674   5.509675\n9848                            storm       39953  11.267548\n29650                   print_results       33812   5.796592\n41675                  personal_yards       31962   6.011538\n35928                         nan_new       28789   3.898947\n33641                       modelu2os       27808  11.509360\n17553                    invert_xaxis       22722  11.728844\n37291  inform_lack_of_coping_capacity       22305   4.274925\n15845                         earning       15365   3.189788\n26961                 convertedsalary       10330   8.264741\n18081                             635        2633   5.456030","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>vocab</th>\n      <th>vocab_freq</th>\n      <th>weights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>37343</th>\n      <td>y_testl11</td>\n      <td>48174</td>\n      <td>3.691251</td>\n    </tr>\n    <tr>\n      <th>39589</th>\n      <td>y_test_cc_lgb</td>\n      <td>48135</td>\n      <td>4.754719</td>\n    </tr>\n    <tr>\n      <th>9856</th>\n      <td>traumatized</td>\n      <td>44062</td>\n      <td>5.444746</td>\n    </tr>\n    <tr>\n      <th>9434</th>\n      <td>trainset</td>\n      <td>43933</td>\n      <td>4.694664</td>\n    </tr>\n    <tr>\n      <th>43744</th>\n      <td>switzerland_nan</td>\n      <td>40674</td>\n      <td>5.509675</td>\n    </tr>\n    <tr>\n      <th>9848</th>\n      <td>storm</td>\n      <td>39953</td>\n      <td>11.267548</td>\n    </tr>\n    <tr>\n      <th>29650</th>\n      <td>print_results</td>\n      <td>33812</td>\n      <td>5.796592</td>\n    </tr>\n    <tr>\n      <th>41675</th>\n      <td>personal_yards</td>\n      <td>31962</td>\n      <td>6.011538</td>\n    </tr>\n    <tr>\n      <th>35928</th>\n      <td>nan_new</td>\n      <td>28789</td>\n      <td>3.898947</td>\n    </tr>\n    <tr>\n      <th>33641</th>\n      <td>modelu2os</td>\n      <td>27808</td>\n      <td>11.509360</td>\n    </tr>\n    <tr>\n      <th>17553</th>\n      <td>invert_xaxis</td>\n      <td>22722</td>\n      <td>11.728844</td>\n    </tr>\n    <tr>\n      <th>37291</th>\n      <td>inform_lack_of_coping_capacity</td>\n      <td>22305</td>\n      <td>4.274925</td>\n    </tr>\n    <tr>\n      <th>15845</th>\n      <td>earning</td>\n      <td>15365</td>\n      <td>3.189788</td>\n    </tr>\n    <tr>\n      <th>26961</th>\n      <td>convertedsalary</td>\n      <td>10330</td>\n      <td>8.264741</td>\n    </tr>\n    <tr>\n      <th>18081</th>\n      <td>635</td>\n      <td>2633</td>\n      <td>5.456030</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":186}],"source":["interpret.sort_values(by='vocab_freq', ascending=False)[interpret['weights'] > 3]"]},{"cell_type":"code","execution_count":196,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"0        0.208923\n1       -0.202469\n2       -0.256652\n3        0.000000\n4       -0.019655\n           ...   \n48988    0.033672\n48989    0.033672\n48990    0.033672\n48991    0.033672\n48992    0.033672\nName: weights, Length: 48993, dtype: float64"},"metadata":{},"execution_count":196}],"source":["interpret['weights']"]},{"cell_type":"code","execution_count":157,"metadata":{},"outputs":[],"source":["interpret = pd.DataFrame()\n","interpret['vocab'] = vocab\n","interpret['vocab_freq'] = vocab_freq\n","interpret['weights'] = weights"]}],"nbformat":4,"nbformat_minor":1,"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"name":"svc.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.8.5 32-bit","language":"python","name":"python_defaultSpec_1597940709819"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5-final"},"deepnote_notebook_id":"de3fccfc-e616-4534-95cc-32b90652859d","deepnote_execution_queue":[]}}